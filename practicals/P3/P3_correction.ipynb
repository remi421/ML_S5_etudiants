{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSzS8JtZnR_V"
      },
      "source": [
        "# Practical session nÂ°3\n",
        "\n",
        "Notions:\n",
        "- Training from scratch\n",
        "- Validation step\n",
        "- Learning curves\n",
        "- Transfer learning\n",
        "- Fine tuning\n",
        "- Freezing\n",
        "\n",
        "Duration: 2 h\n",
        "\n",
        "Now that we have covered the basic building blocks, we will train a Convolutional Neural Network (CNN) on slightly more challenging problems than separation of points in a 2D space:\n",
        "- handwritten digit recognition (part **I.**)\n",
        "- binary classification of photos (part **II.**)\n",
        "\n",
        "The first machine learning problem will give us the opportunity to train a tiny CNN from scratch through a complete training loop (including training and validation steps).\n",
        "An efficient training from scratch on the second problem would need much more images than the few available photos (200). We hence use one of the most interesting features of the neural networks: once trained on a very big dataset on a very general task, they could be \"retrained\" (one says fine tuned) on a very specific task that share the same inputs. As such pretrained neural network are much bigger than our first tiny CNN, a graphics card will be used to significantly speed up the process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.A.** The MNIST Database of Handwritten Digit"
      ],
      "metadata": {
        "id": "wwbAwqVbTxfG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-6auA4Cc6xC"
      },
      "source": [
        "The Database of Handwritten Digit of the NIST (National Institute of Standards and Technologogies) comprises 70,000 black and white  images of handwritten digits of 28x28 pixels. A specific dataset object is allocated to it in the torchvision.datasets module. \\\\\n",
        "The subsequent cells are designed to import packages, download the MNIST database, define dataLoaders and showcase some images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eN2o2vVtaHcE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtLw0uMvrbtj"
      },
      "outputs": [],
      "source": [
        "# transforms (format/normalization)\n",
        "tr=torchvision.transforms.Compose([\n",
        "   torchvision.transforms.ToTensor(),\n",
        "   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "   ])\n",
        "\n",
        "# Definition of training sets:\n",
        "trainval_dataset = datasets.MNIST(root='./data',\n",
        "                                  train=True,\n",
        "                                  download=True,\n",
        "                                  transform=tr)\n",
        "\n",
        "# Split indices for training and validation\n",
        "num_images = len(trainval_dataset)\n",
        "indices = list(range(num_images))\n",
        "split = int(np.floor(0.2 * num_images))  # 20% validation\n",
        "\n",
        "# Shuffle indices\n",
        "np.random.seed(42)  # Seed for reproducibility\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Create train and validation samplers\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "train_size = len(train_sampler)\n",
        "val_size = len(val_sampler)\n",
        "\n",
        "# Definition of the train/val loaders\n",
        "bs = 8\n",
        "num_workers = 2 # try : print(os.cpu_count())\n",
        "\n",
        "train_loader = DataLoader(trainval_dataset, batch_size=bs,\n",
        "                          sampler=train_sampler, num_workers=num_workers)\n",
        "val_loader = DataLoader(trainval_dataset, batch_size=bs,\n",
        "                        sampler=val_sampler, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ5jwbPKarBT"
      },
      "outputs": [],
      "source": [
        "x, t = next(iter(train_loader))\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(8):\n",
        "  plt.subplot(4,2,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(x[i,0,:,:], cmap='gray') #, interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(t[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1**:\n",
        "- Are images sampled by train_loader and val_loader normalized?\n",
        "- How much images are in *train_loader* and *val_loader*?\n",
        "- What will be the role of the validation loader?"
      ],
      "metadata": {
        "id": "9blrzFa2epQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.B.** A vanilla CNN"
      ],
      "metadata": {
        "id": "ao5mfB91ey_5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWHzA-82fq_7"
      },
      "source": [
        "Now, we will define a vanilla CNN with two convolution layers.\n",
        "\n",
        "**Exercise 2:**  Determine *N* in such a way that the network can accept MNIST images as input.\n",
        "How outputs will be interpreted after the training ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BRQ6P0duauRr",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-caf94083627c780a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# N = ...\n",
        "### BEGIN SOLUTION\n",
        "N = 490\n",
        "### END SOLUTION\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(N, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "\n",
        "        # convert an image to a 1D torch.tensor:\n",
        "        x = x.view(-1, N)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.C.** Training of the CNN"
      ],
      "metadata": {
        "id": "LIWGcdOogD0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a CNN, let's define a loss function. Since the log of output probabilities has been computed with *F.log_softmax*, we only need to gather the logits associated with the target classes. This can be done with the torch.gather function (see **P1**), but the standard way in PyTorch is to use *torch.nn.NLLLoss()*."
      ],
      "metadata": {
        "id": "njDxMZUeitWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f_GdrC04hvjL"
      },
      "outputs": [],
      "source": [
        "model = CNN()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# NLLLoss() will have the same effect as torch.gather (see P1)\n",
        "loss_fn =  torch.nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP49HEuzhu8k"
      },
      "source": [
        "A complete training loop has (at least) two phases: weights are updated only in the first phase dedicated to training. During the validation phase, **generalization performance** on independent images is monitored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQq3pNGnuD0"
      },
      "source": [
        "**Exercise 3**:\n",
        "Complete the following code to print the mean loss and the accuracy on the train and validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kWQvoDL4yNAP",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ad40e631509f5fff",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "outputId": "5407986d-fcc1-4e52-809a-d231979c367a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :0\n",
            "train Loss: 0.3199 Acc: 0.8974\n",
            "val Loss: 0.0885 Acc: 0.9729\n",
            "Time: 61 seconds\n",
            "epoch :1\n",
            "train Loss: 0.0641 Acc: 0.9799\n",
            "val Loss: 0.0620 Acc: 0.9804\n",
            "Time: 122 seconds\n",
            "epoch :2\n",
            "train Loss: 0.0485 Acc: 0.9851\n",
            "val Loss: 0.0470 Acc: 0.9865\n",
            "Time: 179 seconds\n",
            "epoch :3\n",
            "train Loss: 0.0375 Acc: 0.9879\n",
            "val Loss: 0.0585 Acc: 0.9827\n",
            "Time: 246 seconds\n",
            "epoch :4\n",
            "train Loss: 0.0309 Acc: 0.9900\n",
            "val Loss: 0.0539 Acc: 0.9863\n",
            "Time: 314 seconds\n",
            "epoch :5\n",
            "train Loss: 0.0264 Acc: 0.9915\n",
            "val Loss: 0.0595 Acc: 0.9869\n",
            "Time: 375 seconds\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "\n",
        "\n",
        "# Initialize time\n",
        "start_time = time.time()\n",
        "\n",
        "# Learning Loop:\n",
        "for epoch in range(6):\n",
        "    print('epoch :' + str(epoch))\n",
        "\n",
        "    running_loss_train = 0.\n",
        "    running_corrects_train = 0.\n",
        "    running_loss_val = 0.\n",
        "    running_corrects_val = 0.\n",
        "\n",
        "    # Training\n",
        "    for x, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        l = loss_fn(output, label)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_train += l.item() * x.shape[0]\n",
        "        running_corrects_train += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_train = running_loss_train / train_size\n",
        "    epoch_acc_train = running_corrects_train.float() / train_size\n",
        "    train_losses.append(epoch_loss_train)\n",
        "    train_accs.append(epoch_acc_train)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'train', epoch_loss_train, epoch_acc_train))\n",
        "\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "\n",
        "    for x, label in val_loader:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            l = loss_fn(output, label)\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_val += l.item() * x.shape[0]\n",
        "        running_corrects_val += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_val = running_loss_val / val_size\n",
        "    epoch_acc_val = running_corrects_val.float() / val_size\n",
        "    val_losses.append(epoch_loss_val)\n",
        "    val_accs.append(epoch_acc_val)\n",
        "\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'val', epoch_loss_val, epoch_acc_val))\n",
        "\n",
        "    # Print elapsed time:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Time: {round(elapsed_time)} seconds')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4**:\n",
        "At each epoch, store the accuracy and the cost function value in the lists *train_losses*, *val_losses*, *train_accs*, and *val_accs*.\n",
        "Plot the **learning curves** over six epochs. \\\\"
      ],
      "metadata": {
        "id": "ltOmpt1BjuSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjUhzOuWuKvU",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-29721af3359f5f0c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.title('evolution of training and validation accuracies')\n",
        "ax.plot(np.arange(6), np.array(train_accs), color = 'r')\n",
        "ax.plot(np.arange(6), np.array(val_accs), color = 'b')\n",
        "ax.legend(['train acc.', 'val acc.'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzEGdnJ-y0mO",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1f710c6281b43308",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "fig2, ax2 = plt.subplots()\n",
        "\n",
        "plt.title('loss = f(epoch)')\n",
        "ax2.plot(np.arange(6), np.array(train_losses), color = 'r')\n",
        "ax2.plot(np.arange(6), np.array(val_losses), color = 'b')\n",
        "ax2.legend(['train losses', 'val losses'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPJ1inr0ru_9"
      },
      "source": [
        "**Exercise 5:** Complete the following perceptron (P60) to directly take MNIST images as input.\n",
        "Compare the standalone perceptron to the CNN in terms of size (number of weights) and performance on a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kTVMO0md1cfA",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-8d7d9ddad78b7109",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class P60(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(P60, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 50)  # 28*28 numel of MNIST images\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flattening x\n",
        "        x = x.view(-1, 28*28)\n",
        "\n",
        "        # apply first layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # apply second layer\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "perceptron = P60()\n",
        "optimizer = torch.optim.Adam(perceptron.parameters(), lr = 0.001)\n",
        "loss_fn =  torch.nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rw9NdP5nz2mg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-478962a7815b241c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "outputId": "ff5540f5-1d04-4eb4-8c03-9d46cd35830a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN: \n",
            "\n",
            " nb of parameters (conv) : 2770\n",
            " nb of parameters (fc) : 25060\n",
            " total: 27830\n",
            "verif : 27830\n",
            "\n",
            "\n",
            "P60: \n",
            "\n",
            "nb of parameters (fc) : 39760\n",
            "verif: 39760\n"
          ]
        }
      ],
      "source": [
        "# Size comparison:\n",
        "\n",
        "# CNN (don't forget the scalar biases, present by default):\n",
        "print(\"CNN: \\n\")\n",
        "print(\" nb of parameters (conv) : \" + str(10*1*5*5 + 10 + 10*10*5*5 + 10))\n",
        "print(\" nb of parameters (fc) : \" + str(490*50 + 50 + 50*10 + 10))\n",
        "print(\" total: \" + str(10*1*5*5 + 10 + 10*10*5*5 + 10 + \\\n",
        "                        490*50 + 50 + 50*10 + 10))\n",
        "\n",
        "# Verification:\n",
        "nb_weights = 0\n",
        "for module in model.modules():\n",
        "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "    for parameter in module.parameters():\n",
        "      nb_weights += torch.numel(parameter)\n",
        "print(\"verif : \" + str(nb_weights))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Perceptron P60:\n",
        "print(\"P60: \\n\")\n",
        "print(\"nb of parameters (fc) : \" + str(28*28*50 + 50 + 50*10 + 10))\n",
        "\n",
        "# Verification:\n",
        "nb_weights = 0\n",
        "for module in perceptron.modules():\n",
        "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "    for parameter in module.parameters():\n",
        "      nb_weights += torch.numel(parameter)\n",
        "print(\"verif: \" + str(nb_weights))\n",
        "\n",
        "# There are more parameters (weights) in the perceptron."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the perceptron\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "\n",
        "\n",
        "# Initialize time\n",
        "start_time = time.time()\n",
        "\n",
        "# Learning Loop:\n",
        "for epoch in range(6):\n",
        "    print('epoch :' + str(epoch))\n",
        "\n",
        "    running_loss_train = 0.\n",
        "    running_corrects_train = 0.\n",
        "    running_loss_val = 0.\n",
        "    running_corrects_val = 0.\n",
        "\n",
        "    # Training\n",
        "    for x, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = perceptron(x)\n",
        "        l = loss_fn(output, label)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_train += l.item() * x.shape[0]\n",
        "        running_corrects_train += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_train = running_loss_train / train_size\n",
        "    epoch_acc_train = running_corrects_train.float() / train_size\n",
        "    train_losses.append(epoch_loss_train)\n",
        "    train_accs.append(epoch_acc_train)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'train', epoch_loss_train, epoch_acc_train))\n",
        "\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "\n",
        "    for x, label in val_loader:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = perceptron(x)\n",
        "            l = loss_fn(output, label)\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_val += l.item() * x.shape[0]\n",
        "        running_corrects_val += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_val = running_loss_val / val_size\n",
        "    epoch_acc_val = running_corrects_val.float() / val_size\n",
        "    val_losses.append(epoch_loss_val)\n",
        "    val_accs.append(epoch_acc_val)\n",
        "\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'val', epoch_loss_val, epoch_acc_val))\n",
        "\n",
        "    # Print elapsed time:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Time: {round(elapsed_time)} seconds')"
      ],
      "metadata": {
        "id": "DLIOkDVdrqeq",
        "outputId": "738c5825-8c3b-41d4-b602-82f6d84e60ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :0\n",
            "train Loss: 0.5630 Acc: 0.8203\n",
            "val Loss: 0.4328 Acc: 0.8635\n",
            "Time: 35 seconds\n",
            "epoch :1\n",
            "train Loss: 0.4327 Acc: 0.8633\n",
            "val Loss: 0.4133 Acc: 0.8723\n",
            "Time: 79 seconds\n",
            "epoch :2\n",
            "train Loss: 0.3970 Acc: 0.8740\n",
            "val Loss: 0.3855 Acc: 0.8767\n",
            "Time: 117 seconds\n",
            "epoch :3\n",
            "train Loss: 0.3743 Acc: 0.8806\n",
            "val Loss: 0.4050 Acc: 0.8737\n",
            "Time: 155 seconds\n",
            "epoch :4\n",
            "train Loss: 0.3658 Acc: 0.8832\n",
            "val Loss: 0.3967 Acc: 0.8781\n",
            "Time: 196 seconds\n",
            "epoch :5\n",
            "train Loss: 0.3498 Acc: 0.8884\n",
            "val Loss: 0.3757 Acc: 0.8836\n",
            "Time: 231 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "12qtwUymACjF",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0292185aff8e14bf",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "outputId": "50b33b36-8785-40a6-c73d-53e2712e6aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images in the test set: 10000\n",
            "epoch :0\n",
            "train Acc. cnn: 0.9882 Acc perceptron: 0.9537\n"
          ]
        }
      ],
      "source": [
        "# Definition of the test set:\n",
        "test_dataset = datasets.MNIST(root='./data',\n",
        "                                  train=False,\n",
        "                                  download=True,\n",
        "                                  transform=tr)\n",
        "\n",
        "# Note that our test test corresponds to the official MNIST validation step\n",
        "num_images = len(test_dataset)\n",
        "print(f\"number of images in the test set: {num_images}\")\n",
        "\n",
        "\n",
        "# Definition of the train/val loaders\n",
        "bs = 8\n",
        "num_workers = 2 # try : print(os.cpu_count())\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=bs,\n",
        "                         num_workers=num_workers)\n",
        "\n",
        "\n",
        "\n",
        "# Performance comparison (on a test set):\n",
        "\n",
        "test_accs_cnn = []\n",
        "test_accs_perceptron = []\n",
        "model.eval()\n",
        "perceptron.eval()\n",
        "\n",
        "# Testing Loop (only one epoch is needed)\n",
        "for epoch in range(1):\n",
        "    print('epoch :' + str(epoch))\n",
        "\n",
        "    running_corrects_test_cnn = 0.\n",
        "    running_corrects_test_perceptron = 0.\n",
        "\n",
        "    # Training\n",
        "    for x, label in test_loader:\n",
        "      with torch.no_grad():\n",
        "        output = model(x)\n",
        "        # Counters:\n",
        "        _, preds = torch.max(output, 1)\n",
        "        running_corrects_test_cnn += torch.sum(preds == label.data)\n",
        "\n",
        "        output = perceptron(x)\n",
        "        # Counters:\n",
        "        _, preds = torch.max(output, 1)\n",
        "        running_corrects_test_perceptron += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate scores and store:\n",
        "    epoch_acc_test_cnn = running_corrects_test_cnn.float() / len(test_dataset)\n",
        "    epoch_acc_test_perceptron = running_corrects_test_perceptron.float() / len(test_dataset)\n",
        "\n",
        "\n",
        "    print('{} Acc. cnn: {:.4f} Acc perceptron: {:.4f}'.format(\n",
        "        'train', epoch_acc_test_cnn, epoch_acc_test_perceptron))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** It is not easy to improve scores with a larger perceptron:"
      ],
      "metadata": {
        "id": "8JY4fk3ejCnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiggerPerceptron(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BiggerPerceptron, self).__init__()\n",
        "        self.fc01 = nn.Linear(28*28, 50)\n",
        "        self.fc02 = nn.Linear(50, 200)\n",
        "        self.fc1 = nn.Linear(200, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc01(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc02(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "y1oT097sjFaB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigger_perceptron = BiggerPerceptron()\n",
        "optimizer = torch.optim.Adam(bigger_perceptron.parameters(), lr = 0.001)\n",
        "loss_fn =  torch.nn.NLLLoss()"
      ],
      "metadata": {
        "id": "ia_1md_JjKVb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bigger_perceptron :\n",
        "nb_weights = 0\n",
        "for module in bigger_perceptron.modules():\n",
        "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "    for parameter in module.parameters():\n",
        "      nb_weights += torch.numel(parameter)\n",
        "print(nb_weights)"
      ],
      "metadata": {
        "id": "E9CnAtMnjM6R",
        "outputId": "22ec3a59-78e1-4fe6-bd90-a86b4c2a2b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the perceptron\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "\n",
        "# Initialize time\n",
        "start_time = time.time()\n",
        "\n",
        "# Learning Loop:\n",
        "for epoch in range(50):\n",
        "    print('epoch :' + str(epoch))\n",
        "\n",
        "    running_loss_train = 0.\n",
        "    running_corrects_train = 0.\n",
        "    running_loss_val = 0.\n",
        "    running_corrects_val = 0.\n",
        "\n",
        "    # Training\n",
        "    for x, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = bigger_perceptron(x)\n",
        "        l = loss_fn(output, label)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_train += l.item() * x.shape[0]\n",
        "        running_corrects_train += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_train = running_loss_train / train_size\n",
        "    epoch_acc_train = running_corrects_train.float() / train_size\n",
        "    train_losses.append(epoch_loss_train)\n",
        "    train_accs.append(epoch_acc_train)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'train', epoch_loss_train, epoch_acc_train))\n",
        "\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "\n",
        "    for x, label in val_loader:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = bigger_perceptron(x)\n",
        "            l = loss_fn(output, label)\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_val += l.item() * x.shape[0]\n",
        "        running_corrects_val += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_val = running_loss_val / val_size\n",
        "    epoch_acc_val = running_corrects_val.float() / val_size\n",
        "    val_losses.append(epoch_loss_val)\n",
        "    val_accs.append(epoch_acc_val)\n",
        "\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'val', epoch_loss_val, epoch_acc_val))\n",
        "\n",
        "    # Print elapsed time:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Time: {round(elapsed_time)} seconds')"
      ],
      "metadata": {
        "id": "zPAvRUQijP2x",
        "outputId": "e019d346-f51a-4ddc-84fa-0e14bcbb6d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :0\n",
            "train Loss: 0.8967 Acc: 0.7137\n",
            "val Loss: 0.6999 Acc: 0.7872\n",
            "Time: 39 seconds\n",
            "epoch :1\n",
            "train Loss: 0.6811 Acc: 0.7994\n",
            "val Loss: 0.6167 Acc: 0.8112\n",
            "Time: 78 seconds\n",
            "epoch :2\n",
            "train Loss: 0.6305 Acc: 0.8166\n",
            "val Loss: 0.6274 Acc: 0.8158\n",
            "Time: 118 seconds\n",
            "epoch :3\n",
            "train Loss: 0.6074 Acc: 0.8238\n",
            "val Loss: 0.6190 Acc: 0.8181\n",
            "Time: 157 seconds\n",
            "epoch :4\n",
            "train Loss: 0.5912 Acc: 0.8285\n",
            "val Loss: 0.5808 Acc: 0.8264\n",
            "Time: 197 seconds\n",
            "epoch :5\n",
            "train Loss: 0.5751 Acc: 0.8347\n",
            "val Loss: 0.5937 Acc: 0.8292\n",
            "Time: 237 seconds\n",
            "epoch :6\n",
            "train Loss: 0.5713 Acc: 0.8335\n",
            "val Loss: 0.5953 Acc: 0.8257\n",
            "Time: 276 seconds\n",
            "epoch :7\n",
            "train Loss: 0.5606 Acc: 0.8372\n",
            "val Loss: 0.5747 Acc: 0.8382\n",
            "Time: 315 seconds\n",
            "epoch :8\n",
            "train Loss: 0.5550 Acc: 0.8384\n",
            "val Loss: 0.5529 Acc: 0.8384\n",
            "Time: 354 seconds\n",
            "epoch :9\n",
            "train Loss: 0.5525 Acc: 0.8407\n",
            "val Loss: 0.5838 Acc: 0.8397\n",
            "Time: 392 seconds\n",
            "epoch :10\n",
            "train Loss: 0.5490 Acc: 0.8409\n",
            "val Loss: 0.5817 Acc: 0.8392\n",
            "Time: 431 seconds\n",
            "epoch :11\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3596d2db433e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigger_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.A.** Load and viz the Hymenoptera dataset:"
      ],
      "metadata": {
        "id": "KtBP0vK4ptvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through a second image classification problem, we focus on two other important aspects of deep learning: speeding up the learning with GPU cards and the ability to use pretrained networks.\n",
        "\n",
        "To illustrate the first aspect, we will use the GPUs available under Google Colab. To do this, before starting this part, go to **Modifier**/**Modifier les param du notebook** and select a GPU."
      ],
      "metadata": {
        "id": "n7AQg7GcpjFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\") # 0 is the index of the GPU\n",
        "  print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "  print('Change the runtime type to GPU')"
      ],
      "metadata": {
        "id": "QXOoCgYPps4b",
        "outputId": "e1cd3cee-6978-48b7-f500-025e41372953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's download inputs (RGB images of bees or ants) and targets (\"bee\" or \"ant\")."
      ],
      "metadata": {
        "id": "yK-4_kJ8eOF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! unzip -qq hymenoptera_data.zip"
      ],
      "metadata": {
        "id": "SXVsxPATp1hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data = 'hymenoptera_data'\n",
        "print(os.listdir(dir_data))"
      ],
      "metadata": {
        "id": "m1t-CYARp6cA",
        "outputId": "1e6729f4-8df0-4a72-cdc1-e4acfcb6e98a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is in a standard format, and we can manipulate it with a ready-to-use dataset object of the datasets.ImageFolder class:"
      ],
      "metadata": {
        "id": "gEHfyTgDp_7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(dir_data, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "print('Dataset sizs:' )\n",
        "print(dataset_sizes)"
      ],
      "metadata": {
        "id": "JrWo5PbKp-ZC",
        "outputId": "85b67af9-a1ce-495b-bce2-05167cc4093b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizs:\n",
            "{'train': 244, 'val': 153}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the provided dataset is very small, we need to maximize its utility. We will produce new images through additional transformations that preserve the nature of the object (data augmentation). \\\\\n",
        "In the code, transforms.*RandomResizedCrop()*, *transforms.RandomHorizontalFlip()* and *transforms.RandomVerticalFlip()* apply horizontal or vertical axis symmetry with a probability of 1/2. Note that these transformations might not be suitable for other datasets like MNIST since the mirror image of a digit is generally not another digit. \\\\\n",
        "Some images are presented below."
      ],
      "metadata": {
        "id": "XWL42ug1qL7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    if ax is None:\n",
        "      plt.imshow(inp)\n",
        "      plt.title(title)\n",
        "    else:\n",
        "      ax.imshow(inp)\n",
        "      ax.set_title(title)"
      ],
      "metadata": {
        "id": "CEyScDXxqQX6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_batch(images, labels, class_names):\n",
        "    num_images = len(images)\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        axs[i].axis('off')\n",
        "        imshow(images[i],axs[i],class_names[labels[i]])\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "class_names = image_datasets['train'].classes\n",
        "# Assuming `inputs` is a batch of images and `classes` are the corresponding class labels\n",
        "plot_batch(inputs, classes, class_names)"
      ],
      "metadata": {
        "id": "vTKsugT-qU7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.B.** Using a Graphics Card:\n",
        "\n",
        "In this part, the lightest of the ResNet architectures is adapted to our binary classification problem and trained over one epoch."
      ],
      "metadata": {
        "id": "qx-bnxr6qiXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6:**\n",
        "\n",
        "- Load an untrained ResNet18. How many total weights does it contain? Check [here](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html).\n",
        "\n",
        "- How many neurons does the last layer of the network have?\n",
        "\n",
        "- Is there a softmax operation at the end of *ResNet.forward()*?\n",
        "\n",
        "- Modify the last layer of the classifier so that it has as many neurons as there are classes in hymenoptera_data."
      ],
      "metadata": {
        "id": "0O6XUNIMqtpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "print(model)\n",
        "nb_weights = 0\n",
        "for module in model.modules():\n",
        "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear)\\\n",
        "                                   or isinstance(module, nn.BatchNorm2d):\n",
        "    for parameter in module.parameters():\n",
        "      nb_weights += torch.numel(parameter)\n",
        "print(nb_weights)"
      ],
      "metadata": {
        "id": "r5lcJpBkqsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neurons in the last layer\n",
        "print(model.fc)\n",
        "print(model.fc.out_features, \"neurons\")\n",
        "# 1000 neurons"
      ],
      "metadata": {
        "id": "N5bI15-vrOfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modification of the last layer of the classifier\n",
        "def get_model(pretrained):\n",
        "  model = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "  num_ftrs = model.fc.in_features\n",
        "  model.fc = nn.Linear(num_ftrs, 2)\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "7Oao8fbBrPKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define the negative log-likelihood as the cost function. To compute the log-likelihood, we could add a LogSoftmax layer to the ResNet. Another common way to do that is to use a loss function that includes *LogSoftmax*. In this regard, in PyTorch,  *nn.CrossEntropyLoss* combines both *LogSoftmax* and *NLLLoss*."
      ],
      "metadata": {
        "id": "5TrL_IUVuXdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gTtQQnZBvxEF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's define a function that incorporates the training loop:"
      ],
      "metadata": {
        "id": "0S4rFWmwvv4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataloaders, model, loss_fn, optimizer, num_epochs=1):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                # Weights are not updated during the validation phase\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "52wyMpfgu8Ik"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7:** With the *train_model* function, train the ResNet over one epoch with mini-batches of 64 images."
      ],
      "metadata": {
        "id": "BbKdWw1XwUoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'val']}"
      ],
      "metadata": {
        "id": "CdSJ9D3KwQqF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 2\n",
        "# Training over 1 epoch:\n",
        "model = get_model(pretrained=False)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "model = train_model(dataloaders, model, loss_fn, optimizer, num_epochs=1)"
      ],
      "metadata": {
        "id": "8meQT6b7yAua",
        "outputId": "e2ebaf24-8808-4e1f-9078-386c9be012dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/0\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6798 Acc: 56.56%\n",
            "val Loss: 0.6767 Acc: 58.82%\n",
            "Training complete in 0m 54s\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.8126 Acc: 50.41%\n",
            "val Loss: 0.7243 Acc: 45.10%\n",
            "Training complete in 0m 51s\n",
            "52.3 s Â± 1.31 s per loop (mean Â± std. dev. of 2 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.C.** Using a Graphics Card:"
      ],
      "metadata": {
        "id": "n9so8NrZeyHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With more than 10 million parameters, training a ResNet18 on a CPU is much slower than the networks in Part I. \\\\\n",
        "Let's repeat the same training using the GPU."
      ],
      "metadata": {
        "id": "ibQvhhc5xE0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Runtime device :{device}')\n",
        "\n",
        "# Load the model to the GPU:\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "v6OSIXSww-pp",
        "outputId": "bb3924e7-11d5-4441-a956-b27cb7fbe52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime device :cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load a torch.tensor on GPU, the syntax is the same:"
      ],
      "metadata": {
        "id": "VFf1g15UxP2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,1,4,4)\n",
        "print(\"On CPU :\\n\",x)\n",
        "x = x.to(device)\n",
        "# Note: You can also use .cuda() without specifying the device name\n",
        "# but this method is not recommended especially in a multi-gpu environment\n",
        "print(\"On GPU :\\n\",x)\n",
        "\n",
        "# bring back the x tensor to the CPU RAM:\n",
        "x = x.to('cpu') # or x.cpu()\n",
        "print('Back to CPU:\\n',x)"
      ],
      "metadata": {
        "id": "Cy1GqLbUxQQd",
        "outputId": "0150bbdf-e4bf-4874-b65b-29b5254a18a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On CPU :\n",
            " tensor([[[[0.8997, 0.3238, 0.1675, 0.0810],\n",
            "          [0.9166, 0.2653, 0.4745, 0.2725],\n",
            "          [0.3267, 0.2187, 0.9921, 0.2195],\n",
            "          [0.6508, 0.7574, 0.6040, 0.5157]]],\n",
            "\n",
            "\n",
            "        [[[0.7806, 0.4837, 0.2521, 0.3249],\n",
            "          [0.6147, 0.6107, 0.5501, 0.8463],\n",
            "          [0.5577, 0.7939, 0.9760, 0.2241],\n",
            "          [0.1178, 0.7931, 0.4396, 0.6614]]]])\n",
            "On GPU :\n",
            " tensor([[[[0.8997, 0.3238, 0.1675, 0.0810],\n",
            "          [0.9166, 0.2653, 0.4745, 0.2725],\n",
            "          [0.3267, 0.2187, 0.9921, 0.2195],\n",
            "          [0.6508, 0.7574, 0.6040, 0.5157]]],\n",
            "\n",
            "\n",
            "        [[[0.7806, 0.4837, 0.2521, 0.3249],\n",
            "          [0.6147, 0.6107, 0.5501, 0.8463],\n",
            "          [0.5577, 0.7939, 0.9760, 0.2241],\n",
            "          [0.1178, 0.7931, 0.4396, 0.6614]]]], device='cuda:0')\n",
            "Back to CPU:\n",
            " tensor([[[[0.8997, 0.3238, 0.1675, 0.0810],\n",
            "          [0.9166, 0.2653, 0.4745, 0.2725],\n",
            "          [0.3267, 0.2187, 0.9921, 0.2195],\n",
            "          [0.6508, 0.7574, 0.6040, 0.5157]]],\n",
            "\n",
            "\n",
            "        [[[0.7806, 0.4837, 0.2521, 0.3249],\n",
            "          [0.6147, 0.6107, 0.5501, 0.8463],\n",
            "          [0.5577, 0.7939, 0.9760, 0.2241],\n",
            "          [0.1178, 0.7931, 0.4396, 0.6614]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 8:**\n",
        "- Complete the fonction *train_model_gpu* to train the model on GPU.\n",
        "- Compare the CPU and GPU training times.\n",
        "- What are the validation scores after 20 epochs on GPUs ?"
      ],
      "metadata": {
        "id": "avLZ9MuvxaYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_gpu(dataloaders, model, loss_fn, optimizer, num_epochs=1):\n",
        "    # Record the starting time\n",
        "    since = time.time()\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    # Calculate and print the total training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rs0k9yzWxhT8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 2\n",
        "model = get_model(pretrained=False).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "model = train_model_gpu(dataloaders, model, loss_fn, optimizer, num_epochs=1)\n"
      ],
      "metadata": {
        "id": "zlYaoJPUyUAD",
        "outputId": "adec8fbb-b900-458d-cf6b-0c4df0e86280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.7066 Acc: 45.90%\n",
            "val Loss: 0.7005 Acc: 45.10%\n",
            "Training complete in 0m 3s\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.7827 Acc: 49.59%\n",
            "val Loss: 0.6860 Acc: 54.25%\n",
            "Training complete in 0m 3s\n",
            "2.96 s Â± 21.8 ms per loop (mean Â± std. dev. of 2 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.D.** Impact of pretraining on performance:"
      ],
      "metadata": {
        "id": "c6p2L66uyIfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training is faster on a GPU, but it only leads to a very poor score, barely better than random chance. To improve performance, a simple idea is to use a network trained on a similar (or more general) task as a starting point for learning. Here, it works particularly well with networks trained on ImageNet, whose convolutional filters are already very rich.\n",
        "\n",
        "**Note:**\n",
        "This method is refered to as **fine-tuning** a **pretrained model**."
      ],
      "metadata": {
        "id": "VooHGE_fyPR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9:** Compare two ResNet18 trainings, one randomly initialized and the other pre-trained, using learning curves, over 25 epochs."
      ],
      "metadata": {
        "id": "PMZ32ZhXy615"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_gpu_(dataloaders, model, loss_fn, optimizer, num_epochs=1):\n",
        "\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Iterate through training and validation phases\n",
        "        for phase in ['train', 'val']:\n",
        "            # Set the model to training mode during the training phase, and evaluation mode during validation\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Initialize counters for loss and correct predictions\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate through batches in the data loader\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # Move inputs and labels to the specified device (GPU)\n",
        "                ### BEGIN SOLUTION\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Zero the gradients in the optimizer (same as in train_model())\n",
        "                ### BEGIN SOLUTION\n",
        "                optimizer.zero_grad()\n",
        "                ### END SOLUTION\n",
        "                # Forward pass: compute model outputs and predictions (same as in train_model())\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    ### BEGIN SOLUTION\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    ### END SOLUTION\n",
        "                    # Backward pass and optimization step if in the training phase (same as in train_model())\n",
        "                    ### BEGIN SOLUTION\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    ### END SOLUTION\n",
        "                # Update counters\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                acc = torch.sum(preds == labels.data)\n",
        "                # The 'acc' tensor is distributed across different parts of the GPU\n",
        "                # Gather the 'acc' tensor on the CPU before accumulation\n",
        "                # running_corrects += ...\n",
        "                ### BEGIN SOLUTION\n",
        "                running_corrects += acc.cpu()\n",
        "                ### END SOLUTION\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            if phase =='train':\n",
        "              train_accs.append(epoch_acc)\n",
        "            elif phase =='val':\n",
        "              val_accs.append(epoch_acc)\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "\n",
        "    # Return the trained model, train_accs and val_accs\n",
        "    return model, train_accs, val_accs"
      ],
      "metadata": {
        "id": "ICM5aJLa2ORy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 25\n",
        "# Learning \"from scratch\" (random weights) :\n",
        "# get the model\n",
        "# Put the model on GPU\n",
        "# get the loss, optimize, the scheduler and starting the training\n",
        "# ...\n",
        "# resnet_scratch, accs_scratch = train(...)\n",
        "\n",
        "resnet_scratch = get_model(pretrained=False)\n",
        "resnet_scratch = resnet_scratch.to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(resnet_scratch.parameters(), lr=0.001,\n",
        "                            momentum=0.9)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10,\n",
        "                                                   gamma=0.1)\n",
        "resnet_scratch, _, accs_scratch =  train_model_gpu_(dataloaders,\n",
        "                                                    resnet_scratch,\n",
        "                                                    loss_function,\n",
        "                                                    optimizer,\n",
        "                                                    num_epochs=max_epochs)"
      ],
      "metadata": {
        "id": "a8vrkAfL0FBq",
        "outputId": "d4549e5a-19d3-4bb6-9c6c-3aadf1e204cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.7118 Acc: 50.41%\n",
            "val Loss: 0.6933 Acc: 54.25%\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.6811 Acc: 55.74%\n",
            "val Loss: 0.6836 Acc: 53.59%\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6609 Acc: 59.43%\n",
            "val Loss: 0.6875 Acc: 50.98%\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6479 Acc: 62.70%\n",
            "val Loss: 0.6856 Acc: 53.59%\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.6172 Acc: 64.34%\n",
            "val Loss: 0.6709 Acc: 54.90%\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.6105 Acc: 64.75%\n",
            "val Loss: 0.6575 Acc: 64.71%\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.6042 Acc: 65.16%\n",
            "val Loss: 0.6507 Acc: 62.09%\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.5938 Acc: 66.80%\n",
            "val Loss: 0.6368 Acc: 62.75%\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.5831 Acc: 68.03%\n",
            "val Loss: 0.6266 Acc: 65.36%\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.5820 Acc: 66.39%\n",
            "val Loss: 0.6123 Acc: 68.63%\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.5667 Acc: 68.44%\n",
            "val Loss: 0.6109 Acc: 66.67%\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.5437 Acc: 71.72%\n",
            "val Loss: 0.6084 Acc: 67.97%\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.5495 Acc: 69.67%\n",
            "val Loss: 0.5904 Acc: 71.24%\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.5546 Acc: 72.13%\n",
            "val Loss: 0.5859 Acc: 70.59%\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.5274 Acc: 72.13%\n",
            "val Loss: 0.5951 Acc: 69.93%\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.5210 Acc: 74.18%\n",
            "val Loss: 0.6034 Acc: 67.97%\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.5273 Acc: 71.72%\n",
            "val Loss: 0.5957 Acc: 67.97%\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.5031 Acc: 70.90%\n",
            "val Loss: 0.6033 Acc: 69.28%\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.5150 Acc: 73.77%\n",
            "val Loss: 0.5898 Acc: 70.59%\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.5014 Acc: 73.77%\n",
            "val Loss: 0.5783 Acc: 74.51%\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.4790 Acc: 74.59%\n",
            "val Loss: 0.5955 Acc: 68.63%\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.4890 Acc: 74.59%\n",
            "val Loss: 0.5972 Acc: 68.63%\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.4910 Acc: 75.00%\n",
            "val Loss: 0.6042 Acc: 68.63%\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.4745 Acc: 73.36%\n",
            "val Loss: 0.6059 Acc: 69.28%\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.4733 Acc: 74.59%\n",
            "val Loss: 0.5770 Acc: 70.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning a pretrained model:\n",
        "# ...\n",
        "# resnet_ft, accs_ft = train(...)\n",
        "\n",
        "resnet_ft = get_model(pretrained=True)\n",
        "\n",
        "resnet_ft = resnet_ft.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(resnet_ft.parameters(), lr=0.001,\n",
        "                            momentum=0.9)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10,\n",
        "                                                   gamma=0.1)\n",
        "resnet_ft, _, accs_ft = train_model_gpu_(dataloaders,\n",
        "                                          resnet_ft,\n",
        "                                          loss_function,\n",
        "                                          optimizer,\n",
        "                                          num_epochs=max_epochs)"
      ],
      "metadata": {
        "id": "ED_6tLDtz_-q",
        "outputId": "5bc17f0a-69b4-4cbb-82af-3a5f3ef4dd55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.7628 Acc: 49.18%\n",
            "val Loss: 0.6632 Acc: 62.75%\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.6195 Acc: 66.39%\n",
            "val Loss: 0.5297 Acc: 74.51%\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.5085 Acc: 77.87%\n",
            "val Loss: 0.4062 Acc: 80.39%\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.3682 Acc: 88.52%\n",
            "val Loss: 0.3212 Acc: 86.93%\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.3127 Acc: 90.16%\n",
            "val Loss: 0.2650 Acc: 91.50%\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.2750 Acc: 90.57%\n",
            "val Loss: 0.2355 Acc: 92.81%\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.2149 Acc: 93.85%\n",
            "val Loss: 0.2170 Acc: 93.46%\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1828 Acc: 95.08%\n",
            "val Loss: 0.2053 Acc: 93.46%\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.1875 Acc: 94.67%\n",
            "val Loss: 0.1952 Acc: 93.46%\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.1712 Acc: 92.62%\n",
            "val Loss: 0.1896 Acc: 94.12%\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1434 Acc: 96.31%\n",
            "val Loss: 0.1856 Acc: 94.77%\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1455 Acc: 95.08%\n",
            "val Loss: 0.1819 Acc: 94.77%\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.1406 Acc: 95.08%\n",
            "val Loss: 0.1789 Acc: 94.77%\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.1334 Acc: 94.67%\n",
            "val Loss: 0.1774 Acc: 94.77%\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.1327 Acc: 95.49%\n",
            "val Loss: 0.1726 Acc: 94.77%\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1117 Acc: 97.54%\n",
            "val Loss: 0.1712 Acc: 94.77%\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1453 Acc: 95.90%\n",
            "val Loss: 0.1722 Acc: 94.77%\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0991 Acc: 97.95%\n",
            "val Loss: 0.1712 Acc: 94.77%\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0933 Acc: 97.95%\n",
            "val Loss: 0.1739 Acc: 94.12%\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0809 Acc: 97.95%\n",
            "val Loss: 0.1753 Acc: 93.46%\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0885 Acc: 99.18%\n",
            "val Loss: 0.1706 Acc: 94.77%\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0866 Acc: 98.77%\n",
            "val Loss: 0.1718 Acc: 94.12%\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1098 Acc: 96.72%\n",
            "val Loss: 0.1703 Acc: 95.42%\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0827 Acc: 97.95%\n",
            "val Loss: 0.1696 Acc: 95.42%\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1200 Acc: 95.90%\n",
            "val Loss: 0.1706 Acc: 95.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "# Plot the data with improved style\n",
        "epochs = np.arange(max_epochs)\n",
        "\n",
        "\n",
        "ax.plot(epochs, 100 * np.array(accs_scratch), color='blue',\n",
        "        label='Training from Scratch', marker='o', linestyle='-', linewidth=2)\n",
        "ax.plot(epochs, 100 * np.array(accs_ft), color='green',\n",
        "        label='Fine Tuning', marker='s', linestyle='-', linewidth=2)\n",
        "\n",
        "# Assuming accs_scratch and accs_ft are dictionaries with 'val' as a key\n",
        "# you can use the following lines\n",
        "#ax.plot(epochs, 100 * np.array(accs_scratch['val']), color='skyblue',\n",
        "#        label='Training from Scratch', marker='o', linestyle='-', linewidth=2)\n",
        "#ax.plot(epochs, 100 * np.array(accs_ft['val']), color='lightgreen',\n",
        "#        label='Fine Tuning', marker='s', linestyle='-', linewidth=2)\n",
        "\n",
        "# Set title and axis labels\n",
        "ax.set_title('Validation Accuracy Over Epochs', fontsize=16)\n",
        "ax.set_ylabel(\"Accuracy (%)\", fontsize=14)\n",
        "ax.set_xlabel(\"Epochs\", fontsize=14)\n",
        "\n",
        "# Set grid for better readability\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "# Add legend with a border and shadow\n",
        "ax.legend(frameon=True, fancybox=True, shadow=True, framealpha=0.9, fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZxxuoGEsnj1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fine-tuning approach has many variations that fit into the broader framework of **transfer learning**. Partial fine-tuning, as illustrated in the following exercise, is one of these variations."
      ],
      "metadata": {
        "id": "ws5pw9cDzLi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 10:** Instead of retraining all the weights, you can simply use the weights of the classifier. This is referred to as *freezing* the other weights during retraining. \\\\\n",
        "Implement this approach and compare it with the previous ones."
      ],
      "metadata": {
        "id": "uK1QhL7YzQhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# freeze all the layers except the classifier (the last dense layers at end)\n",
        "# using this snippet :\n",
        "\n",
        "for module in resnet.modules() :\n",
        "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.BatchNorm2d):\n",
        "    for param in module.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "freezed_resnet = resnet.to(device)\n",
        "# train the model\n",
        "# ...\n",
        "# freezed_resnet, accs_freezing = train(...)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(freezed_resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "freezed_resnet = freezed_resnet.to(device)\n",
        "freezed_resnet, _, accs_freezing = train_model_gpu_(dataloaders,\n",
        "                                                freezed_resnet,\n",
        "                                                loss_function,\n",
        "                                                optimizer,\n",
        "                                                num_epochs=max_epochs)\n"
      ],
      "metadata": {
        "id": "MoD0ajEnzzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "# Plot the data with improved style\n",
        "epochs = np.arange(max_epochs)\n",
        "\n",
        "\n",
        "ax.plot(epochs, 100 * np.array(accs_scratch), color='skyblue',\n",
        "        label='Training from Scratch', marker='o', linestyle='-', linewidth=2)\n",
        "ax.plot(epochs, 100 * np.array(accs_ft), color='lightgreen',\n",
        "        label='Fine Tuning', marker='s', linestyle='-', linewidth=2)\n",
        "ax.plot(epochs, 100 * np.array(accs_freezing), color='g',\n",
        "        label='Fine Tuning with freezed weights', marker='s', linestyle='-', linewidth=2)\n",
        "\n",
        "\n",
        "# Set title and axis labels\n",
        "ax.set_title('Validation Accuracy Over Epochs', fontsize=16)\n",
        "ax.set_ylabel(\"Accuracy (%)\", fontsize=14)\n",
        "ax.set_xlabel(\"Epochs\", fontsize=14)\n",
        "\n",
        "# Set grid for better readability\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "# Add legend with a border and shadow\n",
        "ax.legend(frameon=True, fancybox=True, shadow=True, framealpha=0.9, fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ogrObl50zkyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, for this small dataset, retraining the last layer performs just as well as global training. To conclude, let's make some predictions with the model on the validation dataset:"
      ],
      "metadata": {
        "id": "AN1jCcePzbcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=10):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(25,num_images//5*5))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//5, 5, images_so_far)\n",
        "                ax.axis('off')\n",
        "                imshow(inputs.cpu().data[j],ax,'Predicted: {}'.format(class_names[preds[j]]))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "visualize_model(resnet_ft, num_images=10)"
      ],
      "metadata": {
        "id": "JknOU2Q3zf3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}