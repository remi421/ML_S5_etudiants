{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSzS8JtZnR_V"
      },
      "source": [
        "# Practical session nÂ°3\n",
        "\n",
        "Notions:\n",
        "- Training from scratch\n",
        "- Validation step\n",
        "- Learning curves\n",
        "- Transfer learning\n",
        "- Fine tuning\n",
        "- Freezing\n",
        "\n",
        "Duration: 2 h\n",
        "\n",
        "Now that we have covered the basic building blocks, we will train a Convolutional Neural Network (CNN) on slightly more challenging problems than separation of points in a 2D space:\n",
        "- handwritten digit recognition (part **I.**)\n",
        "- binary classification of photos (part **II.**)\n",
        "\n",
        "The first machine learning problem will give us the opportunity to train a tiny CNN from scratch through a complete training loop (including training and validation steps).\n",
        "An efficient training from scratch on the second problem would need much more images than the few available photos (200). We hence use one of the most interesting features of the neural networks: once trained on a very big dataset on a very general task, they could be \"retrained\" (one says fine tuned) on a very specific task that share the same inputs. As such pretrained neural network are much bigger than our first tiny CNN, a graphics card will be used to significantly speed up the process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.A.** The MNIST Database of Handwritten Digit"
      ],
      "metadata": {
        "id": "wwbAwqVbTxfG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-6auA4Cc6xC"
      },
      "source": [
        "The Database of Handwritten Digit of the NIST (National Institute of Standards and Technologogies) comprises 70,000 black and white  images of handwritten digits of 28x28 pixels. A specific dataset object is allocated to it in the torchvision.datasets module. \\\\\n",
        "The subsequent cells are designed to import packages, download the MNIST database, define dataLoaders and showcase some images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN2o2vVtaHcE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtLw0uMvrbtj"
      },
      "outputs": [],
      "source": [
        "# transforms (format/normalization)\n",
        "tr=torchvision.transforms.Compose([\n",
        "   torchvision.transforms.ToTensor(),\n",
        "   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "   ])\n",
        "\n",
        "# Definition of training sets:\n",
        "trainval_dataset = datasets.MNIST(root='./data',\n",
        "                                  train=True,\n",
        "                                  download=True,\n",
        "                                  transform=tr)\n",
        "\n",
        "# Split indices for training and validation\n",
        "num_images = len(trainval_dataset)\n",
        "indices = list(range(num_images))\n",
        "split = int(np.floor(0.2 * num_images))  # 20% validation\n",
        "\n",
        "# Shuffle indices\n",
        "np.random.seed(42)  # Seed for reproducibility\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Create train and validation samplers\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "train_size = len(train_sampler)\n",
        "val_size = len(val_sampler)\n",
        "\n",
        "# Definition of the train/val loaders\n",
        "bs = 8\n",
        "num_workers = 2 # try : print(os.cpu_count())\n",
        "\n",
        "train_loader = DataLoader(trainval_dataset, batch_size=bs,\n",
        "                          sampler=train_sampler, num_workers=num_workers)\n",
        "val_loader = DataLoader(trainval_dataset, batch_size=bs,\n",
        "                        sampler=val_sampler, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ5jwbPKarBT"
      },
      "outputs": [],
      "source": [
        "x, t = next(iter(train_loader))\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(8):\n",
        "  plt.subplot(4,2,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(x[i,0,:,:], cmap='gray') #, interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(t[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1**:\n",
        "- Are images sampled by train_loader and val_loader normalized?\n",
        "- How much images are in *train_loader* and *val_loader*?\n",
        "- What will be the role of the validation loader?"
      ],
      "metadata": {
        "id": "9blrzFa2epQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.B.** A vanilla CNN"
      ],
      "metadata": {
        "id": "ao5mfB91ey_5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWHzA-82fq_7"
      },
      "source": [
        "Now, we will define a vanilla CNN with two convolution layers.\n",
        "\n",
        "**Exercise 2:**  Determine *N* in such a way that the network can accept MNIST images as input.\n",
        "How outputs will be interpreted after the training ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRQ6P0duauRr",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-caf94083627c780a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# N = ...\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(N, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "\n",
        "        # convert an image to a 1D torch.tensor:\n",
        "        x = x.view(-1, N)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.C.** Training of the CNN"
      ],
      "metadata": {
        "id": "LIWGcdOogD0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a CNN, let's define a loss function. Since the log of output probabilities has been computed with *F.log_softmax*, we only need to gather the logits associated with the target classes. This can be done with the torch.gather function (see **P1**), but the standard way in PyTorch is to use *torch.nn.NLLLoss()*."
      ],
      "metadata": {
        "id": "njDxMZUeitWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_GdrC04hvjL"
      },
      "outputs": [],
      "source": [
        "model = CNN()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# NLLLoss() will have the same effect as torch.gather (see TP1)\n",
        "loss_fn =  torch.nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP49HEuzhu8k"
      },
      "source": [
        "A complete training loop has (at least) two phases: weights are updated only in the first phase dedicated to training. During the validation phase, **generalization performance** on independent images is monitored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQq3pNGnuD0"
      },
      "source": [
        "**Exercise 3**:\n",
        "Complete the following code to print the mean loss and the accuracy on the train and validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHltWFJYCI3n"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "# Initialize time\n",
        "start_time = time.time()\n",
        "\n",
        "# Learning Loop:\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "    running_loss_train = 0.0\n",
        "    running_corrects_train = 0\n",
        "    running_loss_val = 0.0\n",
        "    running_corrects_val = 0\n",
        "\n",
        "    # Phase 1: Training\n",
        "    model.train()  # Set the model to training mode\n",
        "    for x, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_fn(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Update counters:\n",
        "        running_loss_train += loss.item() * x.shape[0]\n",
        "        running_corrects_train += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores (todo):\n",
        "    epoch_loss_train = ...\n",
        "    epoch_acc_train = ...\n",
        "\n",
        "    print(f'Train Loss: {epoch_loss_train:.4f} Acc: {epoch_acc_train:.4f}')\n",
        "\n",
        "    # Phase 2: Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, label in val_loader:\n",
        "            output = model(x)\n",
        "            loss = loss_fn(output, label)\n",
        "\n",
        "            # Get predicted classes:\n",
        "            _, preds = torch.max(output, 1)\n",
        "\n",
        "            # Update counters:\n",
        "            running_loss_val += loss.item() * x.shape[0]\n",
        "            running_corrects_val += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate validation scores (todo):\n",
        "    epoch_loss_val = ...\n",
        "    epoch_acc_val = ...\n",
        "\n",
        "    print(f'Validation Loss: {epoch_loss_val:.4f} Acc: {epoch_acc_val:.4f}')\n",
        "\n",
        "    # Print elapsed time:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Time: {round(elapsed_time)} seconds')\n",
        "\n",
        "    # Update start time for the next epoch\n",
        "    start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWQvoDL4yNAP",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ad40e631509f5fff",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "\n",
        "# Initialize time\n",
        "start_time = time.time()\n",
        "\n",
        "# Learning Loop:\n",
        "for epoch in range(6):\n",
        "    print('epoch :' + str(epoch))\n",
        "\n",
        "    running_loss_train = 0.\n",
        "    running_corrects_train = 0.\n",
        "    running_loss_val = 0.\n",
        "    running_corrects_val = 0.\n",
        "\n",
        "    # Training\n",
        "    for x, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        l = loss_fn(output, label)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_train += l.item() * x.shape[0]\n",
        "        running_corrects_train += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_train = running_loss_train / train_size\n",
        "    epoch_acc_train = running_corrects_train.float() / train_size\n",
        "    train_losses.append(epoch_loss_train)\n",
        "    train_accs.append(epoch_acc_train)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'train', epoch_loss_train, epoch_acc_train))\n",
        "\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "\n",
        "    for x, label in val_loader:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            l = loss_fn(output, label)\n",
        "\n",
        "        # Get predicted classes:\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        # Counters:\n",
        "        running_loss_val += l.item() * x.shape[0]\n",
        "        running_corrects_val += torch.sum(preds == label.data)\n",
        "\n",
        "    # Calculate training scores and store:\n",
        "    epoch_loss_val = running_loss_val / val_size\n",
        "    epoch_acc_val = running_corrects_val.float() / val_size\n",
        "    val_losses.append(epoch_loss_val)\n",
        "    val_accs.append(epoch_acc_val)\n",
        "\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'val', epoch_loss_val, epoch_acc_val))\n",
        "\n",
        "    # Print elapsed time:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Time: {round(elapsed_time)} seconds')\n",
        "\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4**:\n",
        "At each epoch, store the accuracy and the cost function value in the lists *train_losses*, *val_losses*, *train_accs*, and *val_accs*.\n",
        "Plot the **learning curves** over six epochs. \\\\"
      ],
      "metadata": {
        "id": "ltOmpt1BjuSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjUhzOuWuKvU",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-29721af3359f5f0c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.title('evolution of training and validation accuracies')\n",
        "\n",
        "ax.plot( ... , color = 'r')\n",
        "ax.plot( ... , color = 'b')\n",
        "ax.legend(['train acc.', 'val acc.'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzEGdnJ-y0mO",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1f710c6281b43308",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "fig2, ax2 = plt.subplots()\n",
        "plt.title('loss = f(epoch)')\n",
        "ax2.plot( ... ,  color = 'r')\n",
        "ax2.plot( ... , color = 'b')\n",
        "ax2.legend(['train losses', 'val losses'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPJ1inr0ru_9"
      },
      "source": [
        "**Exercise 5:** Complete the following perceptron (P60) to directly take MNIST images as input.\n",
        "Compare the standalone perceptron to the CNN in terms of size (number of weights) and performance on a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTVMO0md1cfA",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-8d7d9ddad78b7109",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class P60(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(P60, self).__init__()\n",
        "        self.fc1 = nn.Linear(... , 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flattening x\n",
        "        x = x.view(-1, ...)\n",
        "\n",
        "        # apply first layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # apply second layer\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "perceptron = P60()\n",
        "optimizer = torch.optim.Adam(perceptron.parameters(), lr = 0.001)\n",
        "loss_fn =  torch.nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw9NdP5nz2mg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-478962a7815b241c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Size comparison:\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12qtwUymACjF",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0292185aff8e14bf",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Performance comparison (on the validation set):\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.A.** Load and viz the Hymenoptera dataset:"
      ],
      "metadata": {
        "id": "KtBP0vK4ptvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through a second image classification problem, we focus on two other important aspects of deep learning: speeding up the learning with GPU cards and the ability to use pretrained networks.\n",
        "\n",
        "To illustrate the first aspect, we will use the GPUs available under Google Colab. To do this, before starting this part, go to **Modifier**/**Modifier les param du notebook** and select a GPU."
      ],
      "metadata": {
        "id": "n7AQg7GcpjFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\") # 0 is the index of the GPU\n",
        "  print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "  print('Change the runtime type to GPU')"
      ],
      "metadata": {
        "id": "QXOoCgYPps4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's download inputs (RGB images of bees or ants) and targets (\"bee\" or \"ant\")."
      ],
      "metadata": {
        "id": "yK-4_kJ8eOF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! unzip -qq hymenoptera_data.zip"
      ],
      "metadata": {
        "id": "SXVsxPATp1hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data = 'hymenoptera_data'\n",
        "print(os.listdir(dir_data))"
      ],
      "metadata": {
        "id": "m1t-CYARp6cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is in a standard format, and we can manipulate it with a ready-to-use dataset object of the datasets.ImageFolder class:"
      ],
      "metadata": {
        "id": "gEHfyTgDp_7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(dir_data, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "print('Dataset sizs:' )\n",
        "print(dataset_sizes)"
      ],
      "metadata": {
        "id": "JrWo5PbKp-ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the provided dataset is very small, we need to maximize its utility. We will produce new images through additional transformations that preserve the nature of the object (data augmentation). \\\\\n",
        "In the code, transforms.*RandomResizedCrop()*, *transforms.RandomHorizontalFlip()* and *transforms.RandomVerticalFlip()* apply horizontal or vertical axis symmetry with a probability of 1/2. Note that these transformations might not be suitable for other datasets like MNIST since the mirror image of a digit is generally not another digit. \\\\\n",
        "Some images are presented below."
      ],
      "metadata": {
        "id": "XWL42ug1qL7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    if ax is None:\n",
        "      plt.imshow(inp)\n",
        "      plt.title(title)\n",
        "    else:\n",
        "      ax.imshow(inp)\n",
        "      ax.set_title(title)"
      ],
      "metadata": {
        "id": "CEyScDXxqQX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_batch(images, labels, class_names):\n",
        "    num_images = len(images)\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        axs[i].axis('off')\n",
        "        imshow(images[i],axs[i],class_names[labels[i]])\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "class_names = image_datasets['train'].classes\n",
        "# Assuming `inputs` is a batch of images and `classes` are the corresponding class labels\n",
        "plot_batch(inputs, classes, class_names)"
      ],
      "metadata": {
        "id": "vTKsugT-qU7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.B.** Using a Graphics Card:\n",
        "\n",
        "In this part, the lightest of the ResNet architectures is adapted to our binary classification problem and trained over one epoch."
      ],
      "metadata": {
        "id": "qx-bnxr6qiXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6:**\n",
        "\n",
        "- Load an untrained ResNet18. How many total weights does it contain? Check [here](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html).\n",
        "\n",
        "- How many neurons does the last layer of the network have?\n",
        "\n",
        "- Is there a softmax operation at the end of *ResNet.forward()*?\n",
        "\n",
        "- Modify the last layer of the classifier so that it has as many neurons as there are classes in hymenoptera_data."
      ],
      "metadata": {
        "id": "0O6XUNIMqtpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "..."
      ],
      "metadata": {
        "id": "r5lcJpBkqsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5bI15-vrOfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modification of the last layer of the classifier\n",
        "def get_model(pretrained):\n",
        "  model = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "  ...\n",
        "\n",
        "  return model\n",
        "\n",
        "model = get_model(False)"
      ],
      "metadata": {
        "id": "7Oao8fbBrPKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define the negative log-likelihood as the cost function. To compute the log-likelihood, we could add a LogSoftmax layer to the ResNet. Another common way to do that is to use a loss function that includes *LogSoftmax*. In this regard, in PyTorch,  *nn.CrossEntropyLoss* combines both *LogSoftmax* and *NLLLoss*."
      ],
      "metadata": {
        "id": "5TrL_IUVuXdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gTtQQnZBvxEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's define a function that incorporates the training loop:"
      ],
      "metadata": {
        "id": "0S4rFWmwvv4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataloaders, model, loss_fn, optimizer, num_epochs=1):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                # Weights are not updated during the validation phase\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {100*epoch_acc:.2f}%')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "52wyMpfgu8Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7:** With the *train_model* function, train the ResNet over one epoch with mini-batches of 64 images."
      ],
      "metadata": {
        "id": "BbKdWw1XwUoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "model = get_model(pretrained=False)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training over 1 epoch:\n",
        "..."
      ],
      "metadata": {
        "id": "CdSJ9D3KwQqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.C.** Using a Graphics Card:"
      ],
      "metadata": {
        "id": "n9so8NrZeyHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With more than 10 million parameters, training a ResNet18 on a CPU is much slower than the networks in Part I. \\\\\n",
        "Let's repeat the same training using the GPU."
      ],
      "metadata": {
        "id": "ibQvhhc5xE0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Runtime device :{device}')\n",
        "\n",
        "# Load the model to the GPU:\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "v6OSIXSww-pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load a torch.tensor on GPU, the syntax is the same:"
      ],
      "metadata": {
        "id": "VFf1g15UxP2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,1,4,4)\n",
        "print(\"On CPU :\\n\",x)\n",
        "x = x.to(device)\n",
        "# Note: You can also use .cuda() without specifying the device name\n",
        "# but this method is not recommended especially in a multi-gpu environment\n",
        "print(\"On GPU :\\n\",x)\n",
        "\n",
        "# bring back the x tensor to the CPU RAM:\n",
        "x = x.to('cpu') # or x.cpu()\n",
        "print('Back to CPU:\\n',x)"
      ],
      "metadata": {
        "id": "Cy1GqLbUxQQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 8:**\n",
        "- Complete the fonction *train_model_gpu* to train the model on GPU.\n",
        "- Compare the CPU and GPU training times.\n",
        "- What are the validation scores after 20 epochs on GPUs ?"
      ],
      "metadata": {
        "id": "avLZ9MuvxaYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_gpu(dataloaders, model, loss_fn, optimizer, num_epochs=1):\n",
        "  ..."
      ],
      "metadata": {
        "id": "rs0k9yzWxhT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II.D.** Impact of pretraining on performance:"
      ],
      "metadata": {
        "id": "c6p2L66uyIfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training is faster on a GPU, but it only leads to a very poor score, barely better than random chance. To improve performance, a simple idea is to use a network trained on a similar (or more general) task as a starting point for learning. Here, it works particularly well with networks trained on ImageNet, whose convolutional filters are already very rich.\n",
        "\n",
        "**Note:**\n",
        "This method is refered to as **fine-tuning** a **pretrained model**."
      ],
      "metadata": {
        "id": "VooHGE_fyPR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9:** Compare two ResNet18 trainings, one randomly initialized and the other pre-trained, using learning curves, over 25 epochs."
      ],
      "metadata": {
        "id": "PMZ32ZhXy615"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 25\n",
        "# Learning \"from scratch\" (random weights) :\n",
        "# get the model\n",
        "# Put the model on GPU\n",
        "# get the loss, optimize, the scheduler and starting the training\n",
        "# ...\n",
        "# resnet_scratch, accs_scratch = train(...)\n",
        "\n"
      ],
      "metadata": {
        "id": "a8vrkAfL0FBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning a pretrained model:\n",
        "# ...\n",
        "# resnet_ft, accs_ft = train(...)\n"
      ],
      "metadata": {
        "id": "ED_6tLDtz_-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_C4VC9cvz6m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fine-tuning approach has many variations that fit into the broader framework of **transfer learning**. Partial fine-tuning, as illustrated in the following exercise, is one of these variations."
      ],
      "metadata": {
        "id": "ws5pw9cDzLi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 10:** Instead of retraining all the weights, you can simply use the weights of the classifier. This is referred to as *freezing* the other weights during retraining. \\\\\n",
        "Implement this approach and compare it with the previous ones."
      ],
      "metadata": {
        "id": "uK1QhL7YzQhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "\n",
        "# freeze all the layers except the classifier (the last dense layers at end)\n",
        "# using this snippet :\n",
        "    ...\n",
        "    for param in module.parameters():\n",
        "      param.requires_grad = False\n",
        "    ...\n"
      ],
      "metadata": {
        "id": "MoD0ajEnzzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogrObl50zkyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, for this small dataset, retraining the last layer performs just as well as global training. To conclude, let's make some predictions with the model on the validation dataset:"
      ],
      "metadata": {
        "id": "AN1jCcePzbcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=10):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(25,num_images//5*5))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//5, 5, images_so_far)\n",
        "                ax.axis('off')\n",
        "                imshow(inputs.cpu().data[j],ax,'Predicted: {}'.format(class_names[preds[j]]))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "JknOU2Q3zf3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}